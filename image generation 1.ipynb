{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\ndiscriminator = keras.Sequential(\n    [\n        keras.Input(shape=(208, 176, 3)),\n        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Flatten(),\n        layers.Dropout(0.2),\n        layers.Dense(1, activation=\"sigmoid\"),\n    ],\n    name=\"discriminator\",\n)\ndiscriminator.summary()\nkeras.utils.plot_model(discriminator, \"discriminator_graph.png\", show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T06:02:16.719236Z","iopub.execute_input":"2022-01-16T06:02:16.719528Z","iopub.status.idle":"2022-01-16T06:02:16.924462Z","shell.execute_reply.started":"2022-01-16T06:02:16.719495Z","shell.execute_reply":"2022-01-16T06:02:16.923719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nlatent_dim = 100\n\ngenerator = keras.Sequential(\n    [\n        keras.Input(shape=(latent_dim,)),\n        layers.Dense(26 * 22 * 128),\n        layers.Reshape((26, 22, 128)),\n        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n    ],\n    name=\"generator\",\n)\ngenerator.summary()\nkeras.utils.plot_model(generator, \"generator_graph.png\", show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T06:07:45.642938Z","iopub.execute_input":"2022-01-16T06:07:45.643614Z","iopub.status.idle":"2022-01-16T06:07:45.899562Z","shell.execute_reply.started":"2022-01-16T06:07:45.643571Z","shell.execute_reply":"2022-01-16T06:07:45.8988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = keras.preprocessing.image_dataset_from_directory('../input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train', label_mode=None, image_size=(208, 176), batch_size=32)\ndataset = dataset.map(lambda x: x / 255.0)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:29:15.126478Z","iopub.execute_input":"2022-01-12T08:29:15.126838Z","iopub.status.idle":"2022-01-12T08:29:16.125749Z","shell.execute_reply.started":"2022-01-12T08:29:15.126803Z","shell.execute_reply":"2022-01-12T08:29:16.124665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GAN(keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n\n    @property\n    def metrics(self):\n        return [self.d_loss_metric, self.g_loss_metric]\n\n    def train_step(self, real_images):\n        # Sample random points in the latent space\n        batch_size = tf.shape(real_images)[0]\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Decode them to fake images\n        generated_images = self.generator(random_latent_vectors)\n\n        # Combine them with real images\n        combined_images = tf.concat([generated_images, real_images], axis=0)\n\n        # Assemble labels discriminating real from fake images\n        labels = tf.concat(\n            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n        )\n        # Add random noise to the labels - important trick!\n        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n\n        # Train the discriminator\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(\n            zip(grads, self.discriminator.trainable_weights)\n        )\n\n        # Sample random points in the latent space\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Assemble labels that say \"all real images\"\n        misleading_labels = tf.zeros((batch_size, 1))\n\n        # Train the generator (note that we should *not* update the weights\n        # of the discriminator)!\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(self.generator(random_latent_vectors))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        # Update metrics\n        self.d_loss_metric.update_state(d_loss)\n        self.g_loss_metric.update_state(g_loss)\n        return {\n            \"d_loss\": self.d_loss_metric.result(),\n            \"g_loss\": self.g_loss_metric.result(),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:29:37.371933Z","iopub.execute_input":"2022-01-12T08:29:37.37234Z","iopub.status.idle":"2022-01-12T08:29:37.389368Z","shell.execute_reply.started":"2022-01-12T08:29:37.372294Z","shell.execute_reply":"2022-01-12T08:29:37.388018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GANMonitor(keras.callbacks.Callback):\n    def __init__(self, num_img=15, latent_dim=128):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n\n    def on_epoch_end(self, epoch, logs=None):\n        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n        generated_images = self.model.generator(random_latent_vectors)\n        generated_images *= 255\n        generated_images.numpy()\n        for i in range(self.num_img):\n            img = keras.preprocessing.image.array_to_img(generated_images[i])\n            img.save(\"generated_img_%03d_%d.jpg\" % (epoch, i))\n            plt.savefig('image_at_epoch_{:04d}.jpg'.format(epoch))\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:30:46.038553Z","iopub.execute_input":"2022-01-12T08:30:46.0389Z","iopub.status.idle":"2022-01-12T08:30:46.047742Z","shell.execute_reply.started":"2022-01-12T08:30:46.038864Z","shell.execute_reply":"2022-01-12T08:30:46.046313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 200 # In practice, use ~100 epochs\n\ngan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\ngan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    loss_fn=keras.losses.BinaryCrossentropy(),\n)\n\ngan.fit(\n    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=15, latent_dim=latent_dim)] \n)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T16:00:30.841832Z","iopub.execute_input":"2022-01-11T16:00:30.84212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% PLOTTING RESULTS (Train vs Validation FOLDER 1)\n\ndef Train_Val_Plot(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,f1,val_f1):\n    \n    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))\n    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('History of Accuracy')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('History of Loss')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Loss')\n    ax2.legend(['training', 'validation'])\n    \n    ax3.plot(range(1, len(auc) + 1), auc)\n    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n    ax3.set_title('History of AUC')\n    ax3.set_xlabel('Epochs')\n    ax3.set_ylabel('AUC')\n    ax3.legend(['training', 'validation'])\n    \n    ax4.plot(range(1, len(precision) + 1), precision)\n    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n    ax4.set_title('History of Precision')\n    ax4.set_xlabel('Epochs')\n    ax4.set_ylabel('Precision')\n    ax4.legend(['training', 'validation'])\n    \n    ax5.plot(range(1, len(f1) + 1), f1)\n    ax5.plot(range(1, len(val_f1) + 1), val_f1)\n    ax5.set_title('History of F1-score')\n    ax5.set_xlabel('Epochs')\n    ax5.set_ylabel('F1 score')\n    ax5.legend(['training', 'validation'])\n\n\n    plt.show()\n    \n\nTrain_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n               history.history['loss'],history.history['val_loss'],\n               history.history['auc'],history.history['val_auc'],\n               history.history['precision'],history.history['val_precision'],\n               history.history['f1_score'],history.history['val_f1_score']\n              )","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:29:16.238888Z","iopub.execute_input":"2022-01-14T14:29:16.239352Z","iopub.status.idle":"2022-01-14T14:29:16.473092Z","shell.execute_reply.started":"2022-01-14T14:29:16.239273Z","shell.execute_reply":"2022-01-14T14:29:16.471495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(train_dataset,\n                        validation_data=valid_dataset,\n                        epochs = 20,\n                        verbose = 1,\n                         callbacks=lr_scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T14:33:26.160668Z","iopub.execute_input":"2022-01-14T14:33:26.160969Z","iopub.status.idle":"2022-01-14T14:33:26.176938Z","shell.execute_reply.started":"2022-01-14T14:33:26.160941Z","shell.execute_reply":"2022-01-14T14:33:26.175576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history.keys()","metadata":{"execution":{"iopub.status.busy":"2021-10-03T05:29:08.022095Z","iopub.execute_input":"2021-10-03T05:29:08.02283Z","iopub.status.idle":"2021-10-03T05:29:08.048891Z","shell.execute_reply.started":"2021-10-03T05:29:08.022793Z","shell.execute_reply":"2021-10-03T05:29:08.046573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_callbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=2),\n    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n]\nmodel.fit(dataset, epochs=10, callbacks=my_callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T05:29:54.13455Z","iopub.execute_input":"2021-10-03T05:29:54.135334Z","iopub.status.idle":"2021-10-03T05:29:54.667643Z","shell.execute_reply.started":"2021-10-03T05:29:54.135293Z","shell.execute_reply":"2021-10-03T05:29:54.666037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}